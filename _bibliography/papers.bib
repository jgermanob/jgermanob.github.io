---
---

@string{aps = {American Physical Society,}}

@article{bel2022overview,
  title={Overview of PAR-MEX at Iberlef 2022: Paraphrase Detection in Spanish Shared Task},
  author={Bel-Enguix, Gemma and Sierra, Gerardo and G{\'o}mez-Adorno, Helena and Torres-Moreno, Juan-Manuel and Ortiz-Barajas, Jesus-German and V{\'a}squez, Juan},
  journal={Procesamiento del Lenguaje Natural},
  bibtex_show={true},
  volume={69},
  pages={255--263},
  year={2022},
  pdf={http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/article/download/6445/3853},
  abstract={Paraphrase detection is an important unresolved task in natural language processing; especially in the Spanish language. In order to address this issue, and contribute to the creation of high-performance paraphrase detection automated systems, we propose a shared task called PAR-MEX. For this task, we created a corpus, in Spanish, with topics in the domain of Mexican gastronomy. Afterwards, the participants in this task submitted their classification results on our corpus. In this paper, we explain the steps followed for the creation of the corpus, we summarize the results obtained by the various participants, and propose some conclusions regarding the paraphrase-detection task in Spanish.}
}

@inproceedings{ortiz2019detection,
  title={Detection of Aggressive Tweets in Mexican Spanish Using Multiple Features with Parameter Optimization.},
  author={Ortiz, Germ{\'a}n and G{\'o}mez-Adorno, Helena and Reyes-Maga{\~n}a, Jorge and Bel-Enguix, Gemma and Sierra, Gerardo},
  booktitle={IberLEF@ SEPLN},
  bibtex_show={true},
  pages={520--525},
  year={2019},
  selected={true},
  pdf={http://ceur-ws.org/Vol-2421/MEX-A3T_paper_5.pdf},
  abstract={This paper explains our approach to Aggressiveness Identification in the MEX-A3T shared task, whose aim is the detection of aggressive tweets. The task proposes a binary classification for every tweet: aggressive and non-aggressive. We approached the problem using linguistically motivated features and several types of n-grams (words, characters, functional words, punctuation symbols, among others). We trained a Support Vector Machine using a combinatorial framework that optimizes the results of the classifier. Our best run achieved an F1-score of 0,4549, which is the 5th best among the twenty-six runs.}
}

@inproceedings{martinez2020enhancing,
  title={Enhancing Job Searches in Mexico City with Language Technologies},
  author={Mart{\'\i}nez, Gerardo Sierra and Bel-Enguix, Gemma and G{\'o}mez-Adorno, Helena and Torres-Moreno, Juan-Manuel and Hern{\'a}ndez-Garc{\'\i}a, Tonatiuh and Guadarrama-Olvera, Julio V and Ortiz-Barajas, Jes{\'u}s-Germ{\'a}n and Rojas, Angela Mar{\'\i}a and Damerau, Tomas and Mart{\'\i}nez, Soledad Arag{\'o}n},
  booktitle={Proceedings of the 1st Workshop on Language Technologies for Government and Public Administration (LT4Gov)},
  bibtex_show={true},
  pages={15--21},
  year={2020},
  pdf={https://aclanthology.org/2020.lt4gov-1.3.pdf},
  abstract={In this paper, we show the enhancing of the Demanded Skills Diagnosis (DiCoDe: Diagnostico de Competencias Demandadas), a system developed by Mexico City's Ministry of Labor and Employment Promotion (STyFE: Secretaria de Trabajo y Fomento del Empleo de la Ciudad de Mexico) that seeks to reduce information asymmetries between job seekers and employers. The project uses webscraping techniques to retrieve job vacancies posted on private job portals on a daily basis and with the purpose of informing training and individual case management policies as well as labor market monitoring. For this purpose, a collaboration project between STyFE and the Language Engineering Group (GIL: Grupo de Ingenieria Linguistica) was established in order to enhance DiCoDe by applying NLP models and semantic analysis. By this collaboration, DiCoDe's job vacancies system's macro-structure and its geographic referencing at the city hall (municipality) level were improved. More specifically, dictionaries were created to identify demanded competencies, skills and abilities (CSA) and algorithms were developed for dynamic classifying of vacancies and identifying terms for searches on free text, in order to improve the results and processing time of queries.}
}

@inproceedings{ortiz2023job,
  title={Job offers classifier using neural networks and oversampling methods},
  author={Ortiz, Germ{\'a}n and Enguix, Gemma Bel and G{\'o}mez-Adorno, Helena and Ameer, Iqra and Sidorov, Grigori},
  booktitle={Recent Developments and the New Directions of Research, Foundations, and Applications: Selected Papers of the 8th World Conference on Soft Computing, February 03--05, 2022, Baku, Azerbaijan, Vol. I},
  bibtex_show={true},
  pages={235--248},
  year={2023},
  organization={Springer},
  selected={true},
  pdf={https://arxiv.org/pdf/2207.06223},
  abstract={Both policy and research benefit from a better understanding of individuals' jobs. However, as large-scale administrative records are increasingly employed to represent labour market activity, new automatic methods to classify jobs will become necessary. We developed an automatic job offers classifier using a dataset collected from the largest job bank in Mexico known as Bumeran5. We applied machine learning algorithms such as Support Vector Machines, Naive-Bayes, Logistic Regression, Random Forest, and deep learning Long-Short Term Memory (LSTM). Using these algorithms, we trained multi-class models to classify job offers in one of the 23 classes (not uniformly distributed): Sales, Administration, Call Center, Technology, Trades, Human Resources, Logistics, Marketing, Health, Gastronomy, Financing, Secretary, Production, Engineering, Education, Design, Legal, Construction, Insurance, Communication, Management, Foreign Trade, and Mining. We used the SMOTE, Geometric-SMOTE, and ADASYN synthetic oversampling algorithms to handle imbalanced classes. The proposed convolutional neural network architecture achieved the best results when applied the Geometric-SMOTE algorithm.}
}

@article{ortiz2022sentence,
  title={Sentence-CROBI: A Simple Cross-Bi-Encoder-Based Neural Network Architecture for Paraphrase Identification},
  author={Ortiz-Barajas, Jesus-German and Bel-Enguix, Gemma and G{\'o}mez-Adorno, Helena},
  journal={Mathematics},
  bibtex_show={true},
  volume={10},
  number={19},
  pages={3578},
  year={2022},
  publisher={MDPI},
  selected={true},
  pdf={https://www.mdpi.com/2227-7390/10/19/3578/pdf},
  abstract={Since the rise of Transformer networks and large language models, cross-encoders have become the dominant architecture for various Natural Language Processing tasks. When dealing with sentence pairs, they can exploit the relationships between those pairs. On the other hand, bi-encoders can obtain a vector given a single sentence and are used in tasks such as textual similarity or information retrieval due to their low computational cost; however, their performance is inferior to that of cross-encoders. In this paper, we present Sentence-CROBI, an architecture that combines cross-encoders and bi-encoders to obtain a global representation of sentence pairs. We evaluated the proposed architecture in the paraphrase identification task using the Microsoft Research Paraphrase Corpus, the Quora Question Pairs dataset, and the PAWS-Wiki dataset. Our model obtains competitive results compared with the state-of-the-art by using model ensembles and a simple model configuration. These results demonstrate that a simple architecture that combines sentence pair and single-sentence representations without using complex pre-training or fine-tuning algorithms is a viable alternative for sentence pair tasks.}
}
